{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project template and data can be found at Udacity - Topic: Data Engineering with AWS, course 2, lesson 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import os\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "    # join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "    # reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "        # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting Cassandra Server Locally with Docker\n",
    "\n",
    "To quickly set up a Cassandra server locally, with your Docker opened, please conduct these provided commands in your terminal:\n",
    "\n",
    "```bash\n",
    "# Pull the latest Cassandra Docker image\n",
    "docker pull cassandra:latest\n",
    "\n",
    "# Create a Docker network for Cassandra\n",
    "docker network create cassandra\n",
    "\n",
    "# Run the Cassandra container\n",
    "docker run --rm -d --name cassandra --hostname cassandra --network cassandra -p 9042:9042 cassandra\n",
    "\n",
    "# Verify that the container is running\n",
    "docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "# Connect to a Cassandra instance on local machine\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "\n",
    "# To establish connection and begin executing queries, we need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keyspace\n",
    "try:\n",
    "    session.execute(\"\"\"CREATE KEYSPACE IF NOT EXISTS data_proj\n",
    "                    WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Keyspace\n",
    "try:\n",
    "    session.set_keyspace('data_proj')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to create queries that help answer the following three questions of the data\n",
    "\n",
    "1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see our data created in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harmonia</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Smith</td>\n",
       "      <td>655.77751</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>583</td>\n",
       "      <td>Sehr kosmisch</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prodigy</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>260.07465</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>583</td>\n",
       "      <td>The Big Gundown</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Smith</td>\n",
       "      <td>205.45261</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>583</td>\n",
       "      <td>Marry Me</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sony Wonder</td>\n",
       "      <td>Samuel</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>218.06975</td>\n",
       "      <td>free</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>597</td>\n",
       "      <td>Blackbird</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Van Halen</td>\n",
       "      <td>Tegan</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Levine</td>\n",
       "      <td>289.38404</td>\n",
       "      <td>paid</td>\n",
       "      <td>Portland-South Portland, ME</td>\n",
       "      <td>602</td>\n",
       "      <td>Best Of Both Worlds (Remastered Album Version)</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist firstName gender  itemInSession  lastName     length level  \\\n",
       "0     Harmonia      Ryan      M              0     Smith  655.77751  free   \n",
       "1  The Prodigy      Ryan      M              1     Smith  260.07465  free   \n",
       "2        Train      Ryan      M              2     Smith  205.45261  free   \n",
       "3  Sony Wonder    Samuel      M              0  Gonzalez  218.06975  free   \n",
       "4    Van Halen     Tegan      F              2    Levine  289.38404  paid   \n",
       "\n",
       "                               location  sessionId  \\\n",
       "0    San Jose-Sunnyvale-Santa Clara, CA        583   \n",
       "1    San Jose-Sunnyvale-Santa Clara, CA        583   \n",
       "2    San Jose-Sunnyvale-Santa Clara, CA        583   \n",
       "3  Houston-The Woodlands-Sugar Land, TX        597   \n",
       "4           Portland-South Portland, ME        602   \n",
       "\n",
       "                                             song  userId  \n",
       "0                                   Sehr kosmisch      26  \n",
       "1                                 The Big Gundown      26  \n",
       "2                                        Marry Me      26  \n",
       "3                                       Blackbird      61  \n",
       "4  Best Of Both Worlds (Remastered Album Version)      80  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('event_datafile_new.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "To answer this question, firstly, I will create a song_info table containing all the required columns: sessionId, itemInSession, artist, song, length. Then, I choose sessionId as the partition key, itemInSession as the clustering column, together I have a unique primary key including sessionId and itemInSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'song_info' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create song_info table\n",
    "query1 = \"CREATE TABLE IF NOT EXISTS song_info\"\n",
    "query1 += \"(sessionId int, itemInSession int, artist text, song text, length float, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query1)\n",
    "    print(\"Table 'song_info' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating table 'song_info':\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert data into song_info table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding='utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query1 = \"INSERT INTO song_info (sessionId, itemInSession, artist, song, length)\"\n",
    "        query1 = query1 + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query1, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: Faithless, Song: Music Matters (Mark Knight Dub), Length: 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "# Conduct query to answer question 1\n",
    "query1 = \"SELECT artist, song, length FROM song_info WHERE sessionId = 338 AND itemInSession = 4\"\n",
    "try:\n",
    "    rows = session.execute(query1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(f\"Artist: {row.artist}, Song: {row.song}, Length: {row.length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "To answer this question, firstly, I will create a song_user_info table containing all the required columns: userId, sessionId, itemInSession, artist, song, firstName, lastName. Then, I choose userId and sessionId as the composite partition key, and itemInSession as the clustering column, together I have a unique primary key including userId, sessionId and itemInSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'song_user_info' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create song_user_info table\n",
    "query2 = \"CREATE TABLE IF NOT EXISTS song_user_info\"\n",
    "query2 += \"(userId int, sessionId int, itemInSession int, artist text, song text, \\\n",
    "           firstName text, lastName text, PRIMARY KEY ((userId, sessionId), itemInSession)) \\\n",
    "           WITH CLUSTERING ORDER BY (itemInSession ASC)\"\n",
    "\n",
    "try:\n",
    "    session.execute(query2)\n",
    "    print(\"Table 'song_user_info' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating table 'song_user_info':\", e)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into song_user_info table\n",
    "with open(file, encoding='utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query2 = \"INSERT INTO song_user_info (userId, sessionId, itemInSession, artist, song, firstName, lastName)\"\n",
    "        query2 = query2 + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query2, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: Down To The Bone, Song: Keep On Keepin' On, First Name: Sylvie, Last Name: Cruz\n",
      "Artist: Three Drives, Song: Greece 2000, First Name: Sylvie, Last Name: Cruz\n",
      "Artist: Sebastien Tellier, Song: Kilometer, First Name: Sylvie, Last Name: Cruz\n",
      "Artist: Lonnie Gordon, Song: Catch You Baby (Steve Pitron & Max Sanna Radio Edit), First Name: Sylvie, Last Name: Cruz\n"
     ]
    }
   ],
   "source": [
    "# Conduct query to answer question 2\n",
    "query2 = \"SELECT artist, song, firstName, lastName FROM song_user_info WHERE userId = 10 AND sessionId = 182\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(f\"Artist: {row.artist}, Song: {row.song}, First Name: {row.firstname}, Last Name: {row.lastname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "To answer this question, firstly, I will create a user_info table containing all the required columns: userId, song, firstName, lastName. Then, I choose song as the partition key, and userId as the clustering column, together I have a unique primary key including song and userId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'user_info' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create user_info table\n",
    "query3 = \"CREATE TABLE IF NOT EXISTS user_info\"\n",
    "query3 += \"(userId int, song text, firstName text, lastName text, PRIMARY KEY (song, userId))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query3)\n",
    "    print(\"Table 'user_info' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating table 'user_info':\", e)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into user_info table\n",
    "with open(file, encoding='utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query3 = \"INSERT INTO user_info (userId, song, firstName, lastName)\"\n",
    "        query3 = query3 + \" VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query3, (int(line[10]), line[9], line[1], line[4]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Name: Jacqueline, Last Name: Lynch\n",
      "First Name: Tegan, Last Name: Levine\n",
      "First Name: Sara, Last Name: Johnson\n"
     ]
    }
   ],
   "source": [
    "# Conduct query to answer question 3\n",
    "query3 = \"SELECT firstName, lastName FROM user_info WHERE song = 'All Hands Against His Own'\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query3)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(f\"First Name: {row.firstname}, Last Name: {row.lastname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped table 'song_info' successfully.\n",
      "\n",
      "Dropped table 'song_user_info' successfully.\n",
      "\n",
      "Dropped table 'user_info' successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    session.execute(\"DROP TABLE IF EXISTS song_info\")\n",
    "    print(\"Dropped table 'song_info' successfully.\")\n",
    "    session.execute(\"DROP TABLE IF EXISTS song_user_info\")\n",
    "    print(\"\")\n",
    "    print(\"Dropped table 'song_user_info' successfully.\")\n",
    "    session.execute(\"DROP TABLE IF EXISTS user_info\")\n",
    "    print(\"\")\n",
    "    print(\"Dropped table 'user_info' successfully.\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deakin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
